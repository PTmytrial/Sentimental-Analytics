{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PTmytrial/Sentimental-Analytics/blob/main/Lexicon_based_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
        "```\n",
        "I love McDonalds!\n",
        "```\n",
        "Your list should be stored in a variable `tweet_0`."
      ],
      "metadata": {
        "id": "XXLVXlwxvQAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhuYLJ9ru3UY",
        "outputId": "6e52c6dd-3b5f-4dd2-f1e0-28a83449cda9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'love', 'McDonalds']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "tweet_0 = ['I','love','McDonalds']\n",
        "tweet_0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
        "```\n",
        "McDonalds: you are so good ...\n",
        "```\n",
        "Your list should be stored in a variable `tweet_1`."
      ],
      "metadata": {
        "id": "sibMSRSkwvZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_1 = ['McDonalds','you','are','so','good']\n",
        "tweet_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPR15yQRxNm7",
        "outputId": "400e08c5-2ca7-4722-cdf1-28e4e00d2af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['McDonalds', 'you', 'are', 'so', 'good']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
        "```\n",
        "This McDonalds hamburger, it is gross\n",
        "```\n",
        "Your list should be stored in a variable `tweet_2`."
      ],
      "metadata": {
        "id": "Nh2axebEyZqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_2 = ['This','McDonalds','hamburger','is','so','gross']\n",
        "tweet_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAGTbXTPyZqU",
        "outputId": "cb8a1f97-5462-405a-9c9b-e17483f83cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'McDonalds', 'hamburger', 'is', 'so', 'gross']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represent this lexicon as a Python dictionary called `lexicon`:\n",
        "\n",
        "```\n",
        "+2.1  love\n",
        "+1.8  good\n",
        "-1.5  gross\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nR2dofHV_dge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lexicon = {'love':2.1,'good':1.8,'gross':-1.5}\n",
        "lexicon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUFEM1dpA6VQ",
        "outputId": "41b3be71-5dff-4af0-fc2c-934abdeabdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'love': 2.1, 'good': 1.8, 'gross': -1.5}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop to iterate over all of the tokens in `tweet_2` and make them lower case."
      ],
      "metadata": {
        "id": "CzJ1Ht1-zZw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tweet_2)):\n",
        "  tweet_2[i] = tweet_2[i].lower()\n",
        "tweet_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4prOUtnDzaOE",
        "outputId": "e1e98a49-cc78-45c9-cc82-5713e290eba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'mcdonalds', 'hamburger', 'is', 'so', 'gross']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop to calculate a sentiment score for `tweet_2` using `lexicon`."
      ],
      "metadata": {
        "id": "BtSJ-32yBbYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = 0\n",
        "for token in tweet_2:\n",
        "  if token in lexicon:\n",
        "    score += lexicon[token]\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc7c323-0407-41f1-eaf6-bbf923c4f3b4",
        "id": "ykReYpiwBbYf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that takes two parameters -- a list of tokens and a lexicon -- and returns a sentiment score. Test-out your function with `tweet_2`."
      ],
      "metadata": {
        "id": "Eak51Y5gB0LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentimentScore(list_of_tokens,lexicon):\n",
        "  score = 0\n",
        "  for token in list_of_tokens:\n",
        "    if token in lexicon:\n",
        "      score += lexicon[token]\n",
        "  return(score)\n",
        "sentimentScore(tweet_2,lexicon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bff674-cf2f-4191-8f2f-52a02ac94c4c",
        "id": "CD_9162rB0LP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that takes a list of tokens as a paramater and makes them lower case. You can repurpose your code from Question 5. Test-out your function with `tweet_1`."
      ],
      "metadata": {
        "id": "Eu1GJe7Z04RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeListOfTokensLowercase(list_of_tokens):\n",
        "  for i in range(len(list_of_tokens)):\n",
        "    list_of_tokens[i] = list_of_tokens[i].lower()\n",
        "\n",
        "makeListOfTokensLowercase(tweet_1)\n",
        "tweet_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2j6XV3003eK",
        "outputId": "2868b0b6-9831-46e3-b2c2-c5e1000dcb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mcdonalds', 'you', 'are', 'so', 'good']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new variable `corpus` that stores the three earlier tweets in a \"list of lists\"."
      ],
      "metadata": {
        "id": "brjrHomcxR3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [tweet_0,tweet_1,tweet_2]\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0D9k0XdzRUR",
        "outputId": "5f07bfed-0f1b-49bb-fe45-80821488439a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I', 'love', 'McDonalds'],\n",
              " ['mcdonalds', 'you', 'are', 'so', 'good'],\n",
              " ['this', 'mcdonalds', 'hamburger', 'is', 'so', 'gross']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop to iterate over all of the tweets in `corpus` and use your function from Question 8 to make all of the tokens lowercase."
      ],
      "metadata": {
        "id": "obzpKZnn-lv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in corpus:\n",
        "  makeListOfTokensLowercase(tweet)\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVPLGpPo-00p",
        "outputId": "1fa5a759-d02b-429c-f506-f5491cae3597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'love', 'mcdonalds'],\n",
              " ['mcdonalds', 'you', 'are', 'so', 'good'],\n",
              " ['this', 'mcdonalds', 'hamburger', 'is', 'so', 'gross']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a for loop and your function from Question 7 to print-out scores for each tweet."
      ],
      "metadata": {
        "id": "S_1GxD65CjRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(corpus)):\n",
        "  score = sentimentScore(corpus[i],lexicon)\n",
        "  print('tweet_'+str(i)+'; score='+str(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O9AvoNSCtdF",
        "outputId": "302a887f-80cd-44d3-89aa-ba61a12f2a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet_0; score=2.1\n",
            "tweet_1; score=1.8\n",
            "tweet_2; score=-1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use your function from Question 7 to score the tweet `McDonalds is not great`."
      ],
      "metadata": {
        "id": "H-5hmNnhDlez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentimentScore(['McDonalds','is','not','good'],lexicon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekJKKy3nDkrD",
        "outputId": "3bac360e-4494-4359-ab7e-207e5529fcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In one or two sentences, explain the pros and cons of our sentiment model."
      ],
      "metadata": {
        "id": "wg8XyVSLEA28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros: simple and easy to implement\n",
        "\n",
        "Cons: word order is ignored (Bag of Words model) leading to problems like in Question 12 where the sentiment score is positive but the tweet is clearly negative"
      ],
      "metadata": {
        "id": "_bu-g5h7EO8I"
      }
    }
  ]
}